{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Training Notebook for Cultivated\n",
    "\n",
    "Notebook to train ML model to discriminate between cultivated and natural vegetation. Text file with extracted data can be downloaded from: Model is trained using data extracted to a CSV file.\n",
    "\n",
    "The version with all pixels can be downloaded from: https://rsg.pml.ac.uk/shared_files/dac/train_input_geomedian_tmad.txt.gz\n",
    "\n",
    "As geomedian and mads are calculated separatly need to combine to a single file using:\n",
    "```python\n",
    "import numpy\n",
    "input_data = numpy.loadtxt(\"geomedian_stats_2015.txt\", skiprows=1)\n",
    "input_data_mads = numpy.loadtxt(\"tmad_stats_2015.txt\", skiprows=1)\n",
    "\n",
    "combined_data = numpy.hstack((input_data, input_data_mads[:,1:]))\n",
    "\n",
    "column_names = 'classnum blue green red nir swir1 swir2 BUI BSI NBI EVI NDWI MSAVI sdev edev bcdev'\n",
    "\n",
    "numpy.savetxt(\"training_data_2015_geomedian_mads_poly_mean\",\n",
    "              combined_data,             \n",
    "              header=column_names, comments='', fmt='%.4f')\n",
    "```\n",
    "\n",
    "A version using the mean value for each feature is in the same repo as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pydotplus\n",
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "+----------------------------------+------+--------------+\n",
    "| Class name                       | Code | Numeric code |\n",
    "+==================================+======+==============+\n",
    "| Cultivated Terrestrial Vegetated | A11  | 111          |\n",
    "+----------------------------------+------+--------------+\n",
    "| Natural Terrestrial Vegetated    | A12  | 112          |\n",
    "+----------------------------------+------+--------------+\n",
    "| Cultivated Aquatic Vegetated     | A23  | 123          |\n",
    "+----------------------------------+------+--------------+\n",
    "| Natural Aquatic Vegetated        | A24  | 124          |\n",
    "+----------------------------------+------+--------------+\n",
    "| Artificial Surface               | B15  | 215          |\n",
    "+----------------------------------+------+--------------+\n",
    "| Natural Surface                  | B16  | 216          |\n",
    "+----------------------------------+------+--------------+\n",
    "| Artificial Water                 | B27  | 227          |\n",
    "+----------------------------------+------+--------------+\n",
    "| Natural Water                    | B28  | 228          |\n",
    "+----------------------------------+------+--------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * numpy.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(numpy.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {111: 'Cultivated Terrestrial Vegetated', 112: 'Natural Terrestrial Vegetated', \n",
    " 123: 'Cultivated Aquatic Vegetated', 124: 'Natural Aquatic Vegetated', \n",
    " 215:'Artificial Surface', 216:'Natural Surface', 227:'Artificial Water', 228:'Natural Water'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up working dir\n",
    "working_dir = '/home/jovyan/LCCS/cultivated_classification_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model input from text file...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "/home/jovyan/LCCS/cultivated_classification_4/training_datatrim.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9a8b417fd49c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading model input from text file...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training_datatrim.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_model_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /home/jovyan/LCCS/cultivated_classification_4/training_datatrim.txt not found."
     ]
    }
   ],
   "source": [
    "# Read in text file\n",
    "# As it takes a while first see if there is a pickled version from a previous run\n",
    "pickled_model_input = os.path.join(working_dir, 'training_data_2015_geomedian_mads_poly_mean_numpy.npy')\n",
    "\n",
    "if os.path.isfile(pickled_model_input):\n",
    "    print('Loading pickled model input file')\n",
    "    model_input = numpy.load(pickled_model_input)\n",
    "else:\n",
    "    print('Reading model input from text file...')\n",
    "    model_input = numpy.loadtxt(os.path.join(working_dir, 'training_datatrim.txt'), skiprows=1)\n",
    "    numpy.save(pickled_model_input, model_input)\n",
    "    \n",
    "# Headers are\n",
    "# classnum blue green red nir swir1 swir2 BUI BSI NBI EVI NDWI MSAVI sdev edev bcdev\n",
    "column_names = 'classnum blue green red nir swir1 swir2 sdev edev bcdev'.split()\n",
    "# column_names = 'classnum BS_PC_10 PV_PC_10 NPV_PC_10 BS_PC_50 PV_PC_50 NPV_PC_50 BS_PC_90 PV_PC_90 NPV_PC_90 blue green red nir swir1 swir2 sdev edev bcdev'.split()\n",
    "\n",
    "column_names_indices = {}\n",
    "\n",
    "for col_num, var_name in enumerate(column_names):\n",
    "    column_names_indices[var_name] = col_num\n",
    "    \n",
    "print(\"Input shape:\",model_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any nans\n",
    "model_input = model_input[~numpy.isnan(model_input).any(axis=1)]\n",
    "print(\"Cleaned input shape:\", model_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data, 80 % is used for training with 20 % held back for testing.\n",
    "# Use class to provide similar distribution across classes\n",
    "# in training and testing data\n",
    "model_train, model_test = model_selection.train_test_split(model_input, stratify=model_input[:,0],\n",
    "                                                           train_size=0.8, random_state=0)\n",
    "\n",
    "print(\"Train shape:\",model_train.shape)\n",
    "print(\"Test shape:\",model_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model\n",
    "# model = RandomForestClassifier(n_estimators=200, n_jobs=-1, verbose=0, oob_score=True)\n",
    "\n",
    "# model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                        max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                        min_samples_leaf=1, min_samples_split=3,\n",
    "#                        min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "#                        n_jobs=-1, oob_score=True, random_state=None, verbose=0,\n",
    "#                        warm_start=False)\n",
    "\n",
    "# Last grid optimisation run run\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=3,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False)\n",
    "\n",
    "model_variables = ['blue', 'green','red', 'nir', 'swir1', 'swir2', 'sdev', 'edev']\n",
    "\n",
    "model_col_indices = []\n",
    "\n",
    "for model_var in model_variables:\n",
    "    model_col_indices.append(column_names_indices[model_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit(model_train[:,model_col_indices], model_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model using data held back for training\n",
    "score = model.score(model_test[:,model_col_indices], model_test[:,0])\n",
    "print(\"Accuracy: {:.03}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable importance\n",
    "for var_name, var_importance in zip(model_variables, model.feature_importances_):\n",
    "    print(\"{}: {:.04}\".format(var_name, var_importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore parameter tuning with Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=-1, verbose=0)\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in numpy.linspace(start = 200, stop = 300, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in numpy.linspace(10, 100, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variables = ['red', 'nir', 'blue', 'green', 'swir1', 'swir2', 'sdev', 'edev']\n",
    "\n",
    "model_col_indices = []\n",
    "\n",
    "for model_var in model_variables:\n",
    "    model_col_indices.append(column_names_indices[model_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rcv = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 80, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "classifier = model_rcv.fit(model_train[:,model_col_indices], model_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.best_params_\n",
    "# {'n_estimators': 266,\n",
    "#  'min_samples_split': 2,\n",
    "#  'min_samples_leaf': 1,\n",
    "#  'max_features': 'auto',\n",
    "#  'max_depth': 37,\n",
    "#  'bootstrap': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 10, n_jobs=-1, verbose=0)\n",
    "base_model.fit( model_train[:,model_col_indices], model_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = model_rcv.best_estimator_\n",
    "random_accuracy = evaluate(best_random, model_test[:,model_col_indices], model_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable importance\n",
    "for var_name, var_importance in zip(model_variables, classifier.feature_importances_):\n",
    "    print(\"{}: {:.04}\".format(var_name, var_importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed parameter tuning with Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "#     'bootstrap': [True],\n",
    "    'max_depth': [25, 30, 35, 40, 45],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'n_estimators': [300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 3, verbose=2, n_jobs = -1)\n",
    "model_grid.fit(model_train[:,model_col_indices], model_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_grid.best_estimator_)\n",
    "grid_accuracy = evaluate(model_grid.best_estimator_, model_test[:,model_col_indices], model_test[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing and assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model using data held back for training\n",
    "score = classifier_grid.score(model_test[:,model_col_indices], model_test[:,0])\n",
    "print(\"Accuracy: {:.03}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable importance\n",
    "for var_name, var_importance in zip(model_variables, classifier.feature_importances_):\n",
    "    print(\"{}: {:.04}\".format(var_name, var_importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model_dict = {}\n",
    "\n",
    "ml_model_dict['variables'] = model_variables\n",
    "ml_model_dict['classes'] = {'Not natural terrestrial vegetation' : 111,\n",
    "                            'Natural terrestrial vegetation ' : 112}\n",
    "ml_model_dict['classifier'] = model\n",
    "\n",
    "# Pickle model\n",
    "with open(os.path.join(working_dir, 'model_pickle.pickle'), 'wb') as f:\n",
    "    pickle.dump(ml_model_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
